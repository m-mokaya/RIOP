{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.5 ('reinvent_shared.v2.1')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n reinvent_shared.v2.1 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# change these paths as required\n",
    "\n",
    "prior = \"{prior location}\"\n",
    "agent = \"{agent location}\"\n",
    "output_dir = \"{results location}\"\n",
    "low = \"{reward min}\" # change this to match property and reward threshold. \n",
    "\n",
    "reinvent_dir = os.path.expanduser(\"{reinvent file location}/Reinvent\")\n",
    "reinvent_env = os.path.expanduser(\"{reinvent file location}/reinvent.v3.0\")\n",
    "\n",
    "# if required, generate a folder to store the results\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dictionary\n",
    "configuration = {\n",
    "    \"version\": 3,                          # we are going to use REINVENT's newest release\n",
    "    \"run_type\": \"reinforcement_learning\"   # other run types: \"sampling\", \"validation\",\n",
    "                                           #                  \"transfer_learning\",\n",
    "                                           #                  \"scoring\" and \"create_model\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration[\"logging\"] = {\n",
    "    \"recipient\": \"local\",                  # either to local logging or use a remote REST-interface\n",
    "    \"logging_frequency\": 50,               # log every x-th steps\n",
    "    \"logging_path\": os.path.join(output_dir, \"progress.log\"), # load this folder in tensorboard\n",
    "    \"result_folder\": output_dir,         # will hold the compounds (SMILES) and summaries\n",
    "    \"job_name\": \"REI Exp 1 (1).\",                # set an arbitrary job name for identification\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the \"parameters\" block\n",
    "configuration[\"parameters\"] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a \"diversity_filter\"\n",
    "configuration[\"parameters\"][\"diversity_filter\"] =  {\n",
    "    \"name\": \"NoFilter\",                    # other options are: \"IdenticalTopologicalScaffold\", \n",
    "                                           # \"IdenticalMurckoScaffold\" and \"ScaffoldSimilarity\"\n",
    "                                           # -> use \"NoFilter\" to disable this feature\n",
    "    \"nbmax\": 25,                           # the bin size; penalization will start once this is exceeded\n",
    "    \"minscore\": 0.4,                       # the minimum total score to be considered for binning\n",
    "    \"minsimilarity\": 0.4                   # the minimum similarity to be placed into the same bin\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the inception (we do not use it in this example, so \"smiles\" is an empty list)\n",
    "configuration[\"parameters\"][\"inception\"] = {\n",
    "    \"smiles\": [],                          # fill in a list of SMILES here that can be used (or leave empty)\n",
    "    \"memory_size\": 100,                    # sets how many molecules are to be remembered\n",
    "    \"sample_size\": 10                      # how many are to be sampled each epoch from the memory\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all \"reinforcement learning\"-specific run parameters\n",
    "configuration[\"parameters\"][\"reinforcement_learning\"] = {\n",
    "    \"prior\": prior, # path to the pre-trained model\n",
    "    \"agent\": agent, # path to the pre-trained model\n",
    "    \"n_steps\": 1000,                       # the number of epochs (steps) to be performed; often 1000\n",
    "    \"sigma\": 128,                          # used to calculate the \"augmented likelihood\", see publication\n",
    "    \"learning_rate\": 0.0001,               # sets how strongly the agent is influenced by each epoch\n",
    "    \"batch_size\": 128,                     # specifies how many molecules are generated per epoch\n",
    "    \"reset\": 0,                            # if not '0', the reset the agent if threshold reached to get\n",
    "                                           # more diverse solutions\n",
    "    \"reset_score_cutoff\": 0.5,             # if resetting is enabled, this is the threshold\n",
    "    \"margin_threshold\": 50                 # specify the (positive) margin between agent and prior\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the scoring function definition and add at the end\n",
    "scoring_function = {\n",
    "    \"name\": \"custom_sum\",              # this is our default one (alternative: \"custom_sum\")\n",
    "    \"parallel\": False,                     # sets whether components are to be executed\n",
    "                                           # in parallel; note, that python uses \"False\" / \"True\"\n",
    "                                           # but the JSON \"false\" / \"true\"\n",
    "\n",
    "    # the \"parameters\" list holds the individual components. Change to alter the reward function.\n",
    "    \"parameters\": [\n",
    "    {\n",
    "    \"component_type\": \"num_hbd_lipinski\",\n",
    "    \"name\": \"HB-donors (Lipinski)\",\n",
    "    \"weight\": 1,\n",
    "    \"specific_parameters\": {\n",
    "        \"transformation\": {\n",
    "            \"transformation_type\": \"step\",\n",
    "            \"low\": low\n",
    "            }\n",
    "        }   \n",
    "    }\n",
    "    ]\n",
    "}\n",
    "configuration[\"parameters\"][\"scoring_function\"] = scoring_function\n",
    "\n",
    "# write the configuration file to the disc\n",
    "configuration_JSON_path = os.path.join(output_dir, \"RL_config.json\")\n",
    "with open(configuration_JSON_path, 'w') as f:\n",
    "    json.dump(configuration, f, indent=4, sort_keys=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 ('reinvent_shared.v2.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86b73bc6140564eb9a98334bb4050586d4ad44f64c8cf7566370db77e7a26ac9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
